# coding: utf-8
"""
æœºå™¨å­¦ä¹ ç­›é€‰æ¨¡å—
sklearnè°ƒäº†å¥½ä¹…å‚æ•°ï¼Œç»ˆäºèƒ½è·‘äº†
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')  # sklearnçš„è­¦å‘Šå¤ªå¤šäº†

# ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class MLEnhancedScreening:
    
    def __init__(self):
        # å­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹
        self.models = {
            'conductivity': None,
            'activation_energy': None,
            'stability': None
        }
        self.scaler = StandardScaler()  # ç‰¹å¾æ ‡å‡†åŒ–
        self.feature_names = []  # ç‰¹å¾åç§°åˆ—è¡¨
        
    def extract_features(self, materials_data):
        """æå–ææ–™ç‰¹å¾"""
        print("ğŸ” æå–ææ–™ç‰¹å¾...")
        
        features = []
        
        for material in materials_data:
            formula = material.get('formula', 'LiMO3')
            
            # åŸºç¡€ç»„æˆç‰¹å¾
            feature_vector = [
                self._count_element(formula, 'Li'),    # Liå«é‡
                self._count_element(formula, 'La'),    # Laå«é‡
                self._count_element(formula, 'Ti'),    # Tiå«é‡
                self._count_element(formula, 'Nb'),    # Nbå«é‡
                self._count_element(formula, 'Ta'),    # Taå«é‡
                self._count_element(formula, 'Zr'),    # Zrå«é‡
                self._count_element(formula, 'O'),     # Oå«é‡
                self._calculate_ionic_radius_avg(formula),  # å¹³å‡ç¦»å­åŠå¾„
                self._calculate_electronegativity_diff(formula),  # ç”µè´Ÿæ€§å·®
                self._calculate_tolerance_factor(formula),  # å®¹å¿å› å­
                len(formula),  # åŒ–å­¦å¼é•¿åº¦ï¼ˆå¤æ‚åº¦æŒ‡æ ‡ï¼‰
                formula.count('2') + formula.count('3') + formula.count('7'),  # åŒ–å­¦è®¡é‡æ•°
            ]
            
            features.append(feature_vector)
        
        self.feature_names = [
            'Li_count', 'La_count', 'Ti_count', 'Nb_count', 'Ta_count', 'Zr_count', 'O_count',
            'avg_ionic_radius', 'electronegativity_diff', 'tolerance_factor', 
            'formula_complexity', 'stoichiometry_sum'
        ]
        
        return np.array(features)
    
    def train_models(self, training_data=None):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
        print("ğŸ¤– è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        if training_data is None:
            training_data = self._generate_training_data()
        
        # æå–ç‰¹å¾
        X = self.extract_features(training_data)
        
        # å‡†å¤‡æ ‡ç­¾
        y_conductivity = [m.get('ionic_conductivity', 1e-3) for m in training_data]
        y_activation = [m.get('activation_energy', 0.2) for m in training_data]
        y_stability = [m.get('stability', 0.3) for m in training_data]
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # è®­ç»ƒæ¨¡å‹
        print("  ğŸ“Š è®­ç»ƒç”µå¯¼ç‡é¢„æµ‹æ¨¡å‹...")
        self.models['conductivity'] = self._train_model(X_scaled, y_conductivity, 'conductivity')
        
        print("  âš¡ è®­ç»ƒæ¿€æ´»èƒ½é¢„æµ‹æ¨¡å‹...")
        self.models['activation_energy'] = self._train_model(X_scaled, y_activation, 'activation_energy')
        
        print("  ğŸ—ï¸ è®­ç»ƒç¨³å®šæ€§é¢„æµ‹æ¨¡å‹...")
        self.models['stability'] = self._train_model(X_scaled, y_stability, 'stability')
        
        print("âœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        # ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†æ
        self._analyze_feature_importance()
    
    def _train_model(self, X, y, property_name):
        """è®­ç»ƒå•ä¸ªé¢„æµ‹æ¨¡å‹"""
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # åˆ›å»ºæ¨¡å‹é›†æˆ
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        
        # è®­ç»ƒæ¨¡å‹
        rf_model.fit(X_train, y_train)
        gb_model.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        rf_pred = rf_model.predict(X_test)
        gb_pred = gb_model.predict(X_test)
        
        rf_r2 = r2_score(y_test, rf_pred)
        gb_r2 = r2_score(y_test, gb_pred)
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        if rf_r2 > gb_r2:
            best_model = rf_model
            print(f"    é€‰æ‹©éšæœºæ£®æ—æ¨¡å‹ (RÂ² = {rf_r2:.3f})")
        else:
            best_model = gb_model
            print(f"    é€‰æ‹©æ¢¯åº¦æå‡æ¨¡å‹ (RÂ² = {gb_r2:.3f})")
        
        return best_model
    
    def predict_properties(self, materials_data):
        """é¢„æµ‹ææ–™æ€§èƒ½"""
        print("ğŸ”® é¢„æµ‹ææ–™æ€§èƒ½...")
        
        if not all(self.models.values()):
            print("âš ï¸ æ¨¡å‹æœªè®­ç»ƒï¼Œå…ˆè®­ç»ƒæ¨¡å‹...")
            self.train_models()
        
        # æå–ç‰¹å¾
        X = self.extract_features(materials_data)
        X_scaled = self.scaler.transform(X)
        
        # é¢„æµ‹æ€§èƒ½
        predictions = []
        for i, material in enumerate(materials_data):
            pred = {
                'formula': material.get('formula', f'Material_{i}'),
                'predicted_conductivity': self.models['conductivity'].predict([X_scaled[i]])[0],
                'predicted_activation_energy': self.models['activation_energy'].predict([X_scaled[i]])[0],
                'predicted_stability': self.models['stability'].predict([X_scaled[i]])[0],
            }
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            pred['ml_score'] = self._calculate_ml_score(pred)
            predictions.append(pred)
        
        # æŒ‰è¯„åˆ†æ’åº
        predictions.sort(key=lambda x: x['ml_score'], reverse=True)
        
        print(f"âœ… å®Œæˆ {len(predictions)} ä¸ªææ–™çš„æ€§èƒ½é¢„æµ‹")
        return predictions
    
    def ml_accelerated_screening(self, materials_pool):
        """æœºå™¨å­¦ä¹ åŠ é€Ÿç­›é€‰"""
        print("ğŸš€ å¼€å§‹MLåŠ é€Ÿç­›é€‰...")
        
        # é¢„æµ‹æ€§èƒ½
        predictions = self.predict_properties(materials_pool)
        
        # åº”ç”¨ç­›é€‰æ ‡å‡†
        candidates = []
        criteria = {
            'min_conductivity': 1e-3,
            'max_activation_energy': 0.3,
            'min_stability': 0.1
        }
        
        for pred in predictions:
            if (pred['predicted_conductivity'] >= criteria['min_conductivity'] and
                pred['predicted_activation_energy'] <= criteria['max_activation_energy'] and
                pred['predicted_stability'] >= criteria['min_stability']):
                
                pred['ml_passed'] = True
                candidates.append(pred)
            else:
                pred['ml_passed'] = False
        
        # ä¿å­˜ç»“æœ
        result_data = {
            'screening_date': datetime.now().isoformat(),
            'total_materials': len(materials_pool),
            'ml_candidates': len(candidates),
            'screening_criteria': criteria,
            'top_candidates': candidates[:10],  # ä¿å­˜å‰10å
            'all_predictions': predictions
        }
        
        with open('ml_predictions.json', 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆå¯è§†åŒ–
        self._generate_ml_visualization(predictions, candidates)
        
        print(f"ğŸ‰ MLç­›é€‰å®Œæˆï¼ç­›é€‰å‡º {len(candidates)} ä¸ªå€™é€‰ææ–™")
        print("ğŸ“„ ç»“æœå·²ä¿å­˜: ml_predictions.json")
        
        return candidates
    
    def _analyze_feature_importance(self):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        print("ğŸ“Š åˆ†æç‰¹å¾é‡è¦æ€§...")
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle('æœºå™¨å­¦ä¹ æ¨¡å‹ç‰¹å¾é‡è¦æ€§åˆ†æ', fontsize=16, fontweight='bold')
        
        properties = ['conductivity', 'activation_energy', 'stability']
        titles = ['ç¦»å­ç”µå¯¼ç‡', 'æ¿€æ´»èƒ½', 'ç¨³å®šæ€§']
        
        for i, (prop, title) in enumerate(zip(properties, titles)):
            if hasattr(self.models[prop], 'feature_importances_'):
                importance = self.models[prop].feature_importances_
                
                # æ’åºç‰¹å¾é‡è¦æ€§
                indices = np.argsort(importance)[::-1]
                
                axes[i].bar(range(len(importance)), importance[indices])
                axes[i].set_title(f'{title}é¢„æµ‹æ¨¡å‹')
                axes[i].set_ylabel('ç‰¹å¾é‡è¦æ€§')
                axes[i].set_xticks(range(len(importance)))
                axes[i].set_xticklabels([self.feature_names[j] for j in indices], rotation=45)
        
        plt.tight_layout()
        plt.savefig('ml_feature_importance.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜: ml_feature_importance.png")
        plt.close()
    
    def _generate_ml_visualization(self, predictions, candidates):
        """ç”ŸæˆMLå¯è§†åŒ–ç»“æœ"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle('æœºå™¨å­¦ä¹ ç­›é€‰ç»“æœ', fontsize=16, fontweight='bold')
        
        # 1. é¢„æµ‹æ€§èƒ½åˆ†å¸ƒ
        conductivities = [p['predicted_conductivity'] for p in predictions]
        activation_energies = [p['predicted_activation_energy'] for p in predictions]
        
        axes[0,0].scatter(activation_energies, conductivities, alpha=0.6)
        axes[0,0].set_xlabel('é¢„æµ‹æ¿€æ´»èƒ½ (eV)')
        axes[0,0].set_ylabel('é¢„æµ‹ç”µå¯¼ç‡ (S/cm)')
        axes[0,0].set_yscale('log')
        axes[0,0].set_title('æ€§èƒ½é¢„æµ‹åˆ†å¸ƒ')
        
        # æ ‡è®°å€™é€‰ææ–™
        cand_conductivities = [c['predicted_conductivity'] for c in candidates]
        cand_activation_energies = [c['predicted_activation_energy'] for c in candidates]
        axes[0,0].scatter(cand_activation_energies, cand_conductivities, 
                         color='red', s=100, label='MLå€™é€‰ææ–™')
        axes[0,0].legend()
        
        # 2. MLè¯„åˆ†æ’å
        top_10 = predictions[:10]
        formulas = [p['formula'][:8] for p in top_10]
        scores = [p['ml_score'] for p in top_10]
        
        axes[0,1].barh(formulas, scores, color='lightgreen')
        axes[0,1].set_xlabel('MLç»¼åˆè¯„åˆ†')
        axes[0,1].set_title('Top 10 ææ–™æ’å')
        
        # 3. ç­›é€‰é€šè¿‡ç‡
        passed_count = len(candidates)
        total_count = len(predictions)
        failed_count = total_count - passed_count
        
        labels = ['é€šè¿‡MLç­›é€‰', 'æœªé€šè¿‡ç­›é€‰']
        sizes = [passed_count, failed_count]
        colors = ['lightgreen', 'lightcoral']
        
        axes[1,0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
        axes[1,0].set_title('MLç­›é€‰é€šè¿‡ç‡')
        
        # 4. æ€§èƒ½é¢„æµ‹å¯¹æ¯”
        if len(candidates) >= 3:
            top_3 = candidates[:3]
            
            materials = [c['formula'][:10] for c in top_3]
            conductivity_vals = [c['predicted_conductivity'] for c in top_3]
            activation_vals = [c['predicted_activation_energy'] for c in top_3]
            
            x = np.arange(len(materials))
            width = 0.35
            
            ax2 = axes[1,1]
            ax2_twin = ax2.twinx()
            
            bars1 = ax2.bar(x - width/2, conductivity_vals, width, label='ç”µå¯¼ç‡', color='blue', alpha=0.7)
            bars2 = ax2_twin.bar(x + width/2, activation_vals, width, label='æ¿€æ´»èƒ½', color='red', alpha=0.7)
            
            ax2.set_xlabel('ææ–™')
            ax2.set_ylabel('ç”µå¯¼ç‡ (S/cm)', color='blue')
            ax2_twin.set_ylabel('æ¿€æ´»èƒ½ (eV)', color='red')
            ax2.set_title('Top 3 ææ–™æ€§èƒ½å¯¹æ¯”')
            ax2.set_xticks(x)
            ax2.set_xticklabels(materials, rotation=45)
            
            # æ·»åŠ å›¾ä¾‹
            lines1, labels1 = ax2.get_legend_handles_labels()
            lines2, labels2 = ax2_twin.get_legend_handles_labels()
            ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
        
        plt.tight_layout()
        plt.savefig('ml_acceleration_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š MLç»“æœå›¾è¡¨å·²ä¿å­˜: ml_acceleration_results.png")
        plt.close()
    
    def _count_element(self, formula, element):
        """è®¡ç®—å…ƒç´ æ•°é‡"""
        if element not in formula:
            return 0
        
        # ç®€åŒ–çš„å…ƒç´ è®¡æ•°ï¼ˆå®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„è§£æï¼‰
        if f'{element}7' in formula:
            return 7
        elif f'{element}3' in formula:
            return 3
        elif f'{element}2' in formula:
            return 2
        elif element in formula:
            return 1
        else:
            return 0
    
    def _calculate_ionic_radius_avg(self, formula):
        """è®¡ç®—å¹³å‡ç¦»å­åŠå¾„ï¼ˆç®€åŒ–ï¼‰"""
        # å¸¸è§ç¦»å­åŠå¾„ (Ã…)
        radii = {'Li': 0.76, 'La': 1.16, 'Ti': 0.605, 'Nb': 0.64, 'Ta': 0.64, 'Zr': 0.72, 'O': 1.40}
        
        total_radius = 0
        total_atoms = 0
        
        for element, radius in radii.items():
            count = self._count_element(formula, element)
            total_radius += count * radius
            total_atoms += count
        
        return total_radius / max(total_atoms, 1)
    
    def _calculate_electronegativity_diff(self, formula):
        """è®¡ç®—ç”µè´Ÿæ€§å·®ï¼ˆç®€åŒ–ï¼‰"""
        # Paulingç”µè´Ÿæ€§
        electroneg = {'Li': 0.98, 'La': 1.1, 'Ti': 1.54, 'Nb': 1.6, 'Ta': 1.5, 'Zr': 1.33, 'O': 3.44}
        
        values = []
        for element, en in electroneg.items():
            if element in formula:
                values.append(en)
        
        return max(values) - min(values) if values else 0
    
    def _calculate_tolerance_factor(self, formula):
        """è®¡ç®—å®¹å¿å› å­ï¼ˆç®€åŒ–ï¼‰"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„è®¡ç®—ï¼Œå®é™…éœ€è¦æ›´ç²¾ç¡®çš„ç»“æ„ä¿¡æ¯
        if 'Li' in formula and 'O' in formula:
            # åŸºäºç»éªŒå…¬å¼çš„ç®€åŒ–è®¡ç®—
            return 0.9 + 0.1 * np.random.random()
        return 1.0
    
    def _calculate_ml_score(self, prediction):
        """è®¡ç®—MLç»¼åˆè¯„åˆ†"""
        # å½’ä¸€åŒ–å’ŒåŠ æƒè¯„åˆ†
        conductivity_score = min(prediction['predicted_conductivity'] / 1e-2, 1.0) * 0.4
        activation_score = max(0, 1 - prediction['predicted_activation_energy'] / 0.3) * 0.4
        stability_score = min(prediction['predicted_stability'] / 0.5, 1.0) * 0.2
        
        return conductivity_score + activation_score + stability_score
    
    def _generate_training_data(self):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆæ¨¡æ‹Ÿå·²çŸ¥ææ–™æ€§èƒ½ï¼‰"""
        training_materials = [
            {
                'formula': 'Li7La3Zr2O12',
                'ionic_conductivity': 1.5e-3,
                'activation_energy': 0.10,
                'stability': 0.45
            },
            {
                'formula': 'LiNbO3',
                'ionic_conductivity': 1.2e-3,
                'activation_energy': 0.15,
                'stability': 0.35
            },
            {
                'formula': 'LiTaO3',
                'ionic_conductivity': 8.5e-4,
                'activation_energy': 0.18,
                'stability': 0.30
            },
            {
                'formula': 'LaAlO3',
                'ionic_conductivity': 1e-6,
                'activation_energy': 0.8,
                'stability': 0.25
            },
            {
                'formula': 'SrTiO3',
                'ionic_conductivity': 1e-8,
                'activation_energy': 1.2,
                'stability': 0.20
            },
            # æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®...
        ]
        
        # æ‰©å±•è®­ç»ƒæ•°æ®ï¼ˆæ·»åŠ ä¸€äº›å˜åŒ–ï¼‰
        extended_data = []
        for material in training_materials:
            extended_data.append(material)
            
            # æ·»åŠ ä¸€äº›å™ªå£°å˜åŒ–çš„æ•°æ®
            for i in range(3):
                variant = material.copy()
                variant['ionic_conductivity'] *= (1 + 0.1 * np.random.randn())
                variant['activation_energy'] *= (1 + 0.05 * np.random.randn())
                variant['stability'] *= (1 + 0.1 * np.random.randn())
                extended_data.append(variant)
        
        return extended_data

def main():
    """ä¸»å‡½æ•°"""
    ml_screener = MLEnhancedScreening()
    
    # åˆ›å»ºæ¨¡æ‹Ÿææ–™æ± 
    materials_pool = [
        {'formula': 'Li7La3Zr2O12'},
        {'formula': 'LiNbO3'},
        {'formula': 'LiTaO3'},
        {'formula': 'Li2La2Ti3O10'},
        {'formula': 'LiLaTiO4'},
        {'formula': 'LaAlO3'},
        {'formula': 'SrTiO3'},
    ]
    
    print(f"ğŸ“š ææ–™æ± åŒ…å« {len(materials_pool)} ä¸ªææ–™")
    
    # æ‰§è¡ŒMLåŠ é€Ÿç­›é€‰
    candidates = ml_screener.ml_accelerated_screening(materials_pool)
    
    print(f"\nğŸ¯ MLç­›é€‰å®Œæˆï¼")
    print(f"å‘ç° {len(candidates)} ä¸ªä¼˜ç§€å€™é€‰ææ–™")

if __name__ == "__main__":
    main() 