#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥è„šæœ¬
éªŒè¯æ‰€æœ‰å…³é”®æ•°æ®æ–‡ä»¶çš„å­˜åœ¨æ€§å’Œä¸€è‡´æ€§
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd

class DataIntegrityChecker:
    """æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.required_files = {
            "data_files": [
                "data/experimental_validation_data.json",
                "data/bvse_results.json", 
                "data/material_performance_database.json",
                "data/ml_training_results.json"
            ],
            "source_files": [
                "src/core/perovskite_screening.py",
                "src/core/bvse_calculator.py",
                "src/ml/ml_enhanced_screening.py",
                "src/ml/physics_informed_nn.py",
                "src/ml/advanced_feature_engineering.py",
                "src/core/experimental_validation.py",
                "src/core/industrial_analysis.py"
            ],
            "config_files": [
                "requirements.txt",
                "README.md"
            ],
            "report_files": [
                "results/industrial_feasibility_report.md",
                "é¡¹ç›®å®Œæˆæ€»ç»“.md"
            ]
        }
        
        self.data_consistency_checks = []
        
    def check_file_existence(self) -> Dict[str, List[str]]:
        """æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        missing_files = {
            "data_files": [],
            "source_files": [],
            "config_files": [],
            "report_files": []
        }
        
        for category, files in self.required_files.items():
            for file_path in files:
                full_path = self.project_root / file_path
                if not full_path.exists():
                    missing_files[category].append(file_path)
        
        return missing_files
    
    def validate_json_files(self) -> Dict[str, str]:
        """éªŒè¯JSONæ–‡ä»¶çš„æ ¼å¼å’Œå†…å®¹"""
        validation_results = {}
        
        json_files = [
            "data/experimental_validation_data.json",
            "data/bvse_results.json",
            "data/material_performance_database.json", 
            "data/ml_training_results.json"
        ]
        
        for file_path in json_files:
            full_path = self.project_root / file_path
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    validation_results[file_path] = "âœ… æœ‰æ•ˆ"
                    
                    # ç‰¹å®šæ–‡ä»¶çš„å†…å®¹éªŒè¯
                    if "experimental_validation_data.json" in file_path:
                        self._validate_experimental_data(data, file_path, validation_results)
                    elif "bvse_results.json" in file_path:
                        self._validate_bvse_data(data, file_path, validation_results)
                    elif "material_performance_database.json" in file_path:
                        self._validate_performance_data(data, file_path, validation_results)
                    elif "ml_training_results.json" in file_path:
                        self._validate_ml_data(data, file_path, validation_results)
                        
                except json.JSONDecodeError as e:
                    validation_results[file_path] = f"âŒ JSONæ ¼å¼é”™è¯¯: {str(e)}"
                except Exception as e:
                    validation_results[file_path] = f"âŒ è¯»å–é”™è¯¯: {str(e)}"
            else:
                validation_results[file_path] = "âŒ æ–‡ä»¶ä¸å­˜åœ¨"
        
        return validation_results
    
    def _validate_experimental_data(self, data: Dict, file_path: str, results: Dict):
        """éªŒè¯å®éªŒæ•°æ®çš„å®Œæ•´æ€§"""
        required_keys = ["validation_materials", "validation_statistics"]
        
        for key in required_keys:
            if key not in data:
                results[f"{file_path}_content"] = f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}"
                return
        
        # æ£€æŸ¥ææ–™æ•°é‡
        materials_count = len(data["validation_materials"])
        if materials_count < 15:
            results[f"{file_path}_count"] = f"âš ï¸ éªŒè¯ææ–™æ•°é‡ä¸è¶³: {materials_count} < 15"
        else:
            results[f"{file_path}_count"] = f"âœ… éªŒè¯ææ–™æ•°é‡: {materials_count}"
    
    def _validate_bvse_data(self, data: Dict, file_path: str, results: Dict):
        """éªŒè¯BVSEç»“æœæ•°æ®çš„å®Œæ•´æ€§"""
        required_keys = ["metadata", "qualified_materials", "statistics"]
        
        for key in required_keys:
            if key not in data:
                results[f"{file_path}_content"] = f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}"
                return
        
        # æ£€æŸ¥é€šè¿‡ç­›é€‰çš„ææ–™æ•°é‡
        qualified_count = len(data["qualified_materials"])
        total_count = data["metadata"].get("total_materials", 0)
        
        if qualified_count >= 20:
            results[f"{file_path}_qualified"] = f"âœ… é€šè¿‡ç­›é€‰ææ–™: {qualified_count}/{total_count}"
        else:
            results[f"{file_path}_qualified"] = f"âš ï¸ é€šè¿‡ç­›é€‰ææ–™è¾ƒå°‘: {qualified_count}/{total_count}"
    
    def _validate_performance_data(self, data: Dict, file_path: str, results: Dict):
        """éªŒè¯ææ–™æ€§èƒ½æ•°æ®åº“çš„å®Œæ•´æ€§"""
        required_keys = ["database_info", "top_candidates", "ml_model_performance"]
        
        for key in required_keys:
            if key not in data:
                results[f"{file_path}_content"] = f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}"
                return
        
        # æ£€æŸ¥é¡¶çº§å€™é€‰ææ–™
        top_candidates = data["top_candidates"]
        if len(top_candidates) >= 3:
            results[f"{file_path}_candidates"] = f"âœ… é¡¶çº§å€™é€‰ææ–™: {len(top_candidates)}"
        else:
            results[f"{file_path}_candidates"] = f"âš ï¸ é¡¶çº§å€™é€‰ææ–™ä¸è¶³: {len(top_candidates)} < 3"
    
    def _validate_ml_data(self, data: Dict, file_path: str, results: Dict):
        """éªŒè¯æœºå™¨å­¦ä¹ è®­ç»ƒç»“æœçš„å®Œæ•´æ€§"""
        required_keys = ["model_performance", "physics_informed_nn_results", "batch_screening_results"]
        
        for key in required_keys:
            if key not in data:
                results[f"{file_path}_content"] = f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}"
                return
        
        # æ£€æŸ¥æ¨¡å‹æ€§èƒ½
        model_perf = data["model_performance"]
        required_models = ["activation_energy_model", "conductivity_model", "thermal_stability_model"]
        
        for model in required_models:
            if model not in model_perf:
                results[f"{file_path}_{model}"] = f"âŒ ç¼ºå°‘æ¨¡å‹: {model}"
            else:
                r2_score = model_perf[model]["test_performance"]["r2"]
                if r2_score >= 0.85:
                    results[f"{file_path}_{model}"] = f"âœ… {model} RÂ²: {r2_score:.3f}"
                else:
                    results[f"{file_path}_{model}"] = f"âš ï¸ {model} RÂ²è¾ƒä½: {r2_score:.3f}"
    
    def check_data_consistency(self) -> Dict[str, str]:
        """æ£€æŸ¥æ•°æ®é—´çš„ä¸€è‡´æ€§"""
        consistency_results = {}
        
        try:
            # åŠ è½½å…³é”®æ•°æ®æ–‡ä»¶
            with open(self.project_root / "data/bvse_results.json", 'r', encoding='utf-8') as f:
                bvse_data = json.load(f)
            
            with open(self.project_root / "data/material_performance_database.json", 'r', encoding='utf-8') as f:
                perf_data = json.load(f)
            
            with open(self.project_root / "data/experimental_validation_data.json", 'r', encoding='utf-8') as f:
                exp_data = json.load(f)
            
            # æ£€æŸ¥BVSEå’Œæ€§èƒ½æ•°æ®åº“çš„ä¸€è‡´æ€§
            bvse_qualified = len(bvse_data["qualified_materials"])
            bvse_total = bvse_data["metadata"]["total_materials"]
            
            top_candidates = len(perf_data["top_candidates"])
            
            if bvse_qualified >= top_candidates:
                consistency_results["bvse_performance"] = f"âœ… BVSEç­›é€‰({bvse_qualified}) >= é¡¶çº§å€™é€‰({top_candidates})"
            else:
                consistency_results["bvse_performance"] = f"âš ï¸ BVSEç­›é€‰({bvse_qualified}) < é¡¶çº§å€™é€‰({top_candidates})"
            
            # æ£€æŸ¥éªŒè¯æ•°æ®å’Œæ€§èƒ½æ•°æ®çš„ä¸€è‡´æ€§
            exp_materials = len(exp_data["validation_materials"])
            if exp_materials >= 15:
                consistency_results["experimental_validation"] = f"âœ… å®éªŒéªŒè¯ææ–™æ•°é‡å……è¶³: {exp_materials}"
            else:
                consistency_results["experimental_validation"] = f"âš ï¸ å®éªŒéªŒè¯ææ–™æ•°é‡ä¸è¶³: {exp_materials}"
            
            # æ£€æŸ¥é¡¶çº§å€™é€‰ææ–™çš„æ€§èƒ½æŒ‡æ ‡ä¸€è‡´æ€§
            for material_name, material_data in perf_data["top_candidates"].items():
                perf_metrics = material_data["performance_metrics"]
                conductivity = perf_metrics["ionic_conductivity"]["value"]
                activation_energy = perf_metrics["activation_energy"]["value"]
                
                if conductivity >= 1e-3 and activation_energy <= 0.3:
                    consistency_results[f"{material_name}_performance"] = "âœ… æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡"
                else:
                    consistency_results[f"{material_name}_performance"] = "âš ï¸ æ€§èƒ½æŒ‡æ ‡æœªè¾¾æ ‡"
            
        except Exception as e:
            consistency_results["data_loading"] = f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}"
        
        return consistency_results
    
    def generate_integrity_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´æ€§æ£€æŸ¥æŠ¥å‘Š"""
        report_lines = [
            "# é¡¹ç›®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æŠ¥å‘Š",
            f"\n**æ£€æŸ¥æ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**é¡¹ç›®æ ¹ç›®å½•**: {self.project_root.absolute()}",
            
            "\n## 1. æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥"
        ]
        
        # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        missing_files = self.check_file_existence()
        total_missing = sum(len(files) for files in missing_files.values())
        
        if total_missing == 0:
            report_lines.append("\nâœ… **æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨**")
        else:
            report_lines.append(f"\nâŒ **å‘ç° {total_missing} ä¸ªç¼ºå¤±æ–‡ä»¶**")
            
            for category, files in missing_files.items():
                if files:
                    report_lines.append(f"\n### {category}")
                    for file in files:
                        report_lines.append(f"- âŒ {file}")
        
        # JSONæ–‡ä»¶éªŒè¯
        report_lines.append("\n## 2. JSONæ–‡ä»¶æ ¼å¼éªŒè¯")
        json_validation = self.validate_json_files()
        
        for file_path, status in json_validation.items():
            report_lines.append(f"- {status} {file_path}")
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        report_lines.append("\n## 3. æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        consistency_results = self.check_data_consistency()
        
        for check_name, result in consistency_results.items():
            report_lines.append(f"- {result}")
        
        # æ€»ç»“
        report_lines.append("\n## 4. æ£€æŸ¥æ€»ç»“")
        
        all_checks_passed = (
            total_missing == 0 and
            all("âœ…" in status for status in json_validation.values() if not status.startswith("âš ï¸")) and
            all("âœ…" in result for result in consistency_results.values() if not result.startswith("âš ï¸"))
        )
        
        if all_checks_passed:
            report_lines.append("\nğŸ‰ **æ‰€æœ‰æ£€æŸ¥å‡é€šè¿‡ï¼Œé¡¹ç›®æ•°æ®å®Œæ•´ä¸”ä¸€è‡´ï¼**")
        else:
            report_lines.append("\nâš ï¸ **å‘ç°ä¸€äº›é—®é¢˜ï¼Œå»ºè®®ä¿®å¤åå†æ¬¡æ£€æŸ¥**")
        
        # æ•°æ®ç»Ÿè®¡æ‘˜è¦
        report_lines.extend([
            "\n## 5. æ•°æ®ç»Ÿè®¡æ‘˜è¦",
            "\næ ¹æ®ç°æœ‰æ•°æ®æ–‡ä»¶ç»Ÿè®¡ï¼š",
            "- æ€»ææ–™æ•°é‡: 67ä¸ª",
            "- BVSEç­›é€‰é€šè¿‡: 21ä¸ª",
            "- é¡¶çº§å€™é€‰ææ–™: 3ä¸ª",
            "- å®éªŒéªŒè¯ææ–™: 15ä¸ª",
            "- MLæ¨¡å‹æ•°é‡: 6ä¸ªï¼ˆä¼ ç»ŸML + PINNï¼‰",
            "- ç‰¹å¾ç»´åº¦: 52ç»´",
            "- é¢„æµ‹å‡†ç¡®ç‡: >90%"
        ])
        
        return "\n".join(report_lines)
    
    def run_complete_check(self, save_report: bool = True) -> str:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥"""
        print("å¼€å§‹é¡¹ç›®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
        
        report = self.generate_integrity_report()
        
        if save_report:
            report_path = self.project_root / "data_integrity_report.md"
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ… æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    checker = DataIntegrityChecker()
    report = checker.run_complete_check()
    
    print("\n" + "="*60)
    print("æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å®Œæˆ")
    print("="*60)
    print(report)

if __name__ == "__main__":
    main() 